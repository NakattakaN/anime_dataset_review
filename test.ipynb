{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68ec41b5",
   "metadata": {},
   "source": [
    "The loading of the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4dca452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading Datasets ---\n",
      "Loading AniList data from Datasets\\Holy_Dataset\\anilist_anime_data_complete.csv...\n",
      "✅ Loaded AniList Data: 20099 rows\n",
      "Loading MAL data from Datasets\\anime-dataset-2023.csv...\n",
      "✅ Loaded MAL Data: 24905 rows\n",
      "Loading Offline Database from Datasets\\anime-offline-database.json...\n",
      "✅ Loaded Offline DB: 39277 rows\n",
      "Loading User XML from Datasets\\anilist.xml...\n",
      "✅ Loaded User Data: 328 entries\n",
      "\n",
      "--- Previews ---\n",
      "\n",
      "AniList Sample:\n",
      "                title_english  averageScore  popularity\n",
      "0  Tales of the Street Corner          62.0        2046\n",
      "1                         NaN          57.0         409\n",
      "2        Kimba the White Lion          61.0        2449\n",
      "\n",
      "User List Sample:\n",
      "     series_title my_score  my_status\n",
      "0  Bungaku Shoujo        6  Completed\n",
      "1  86: Eighty Six        7  Completed\n",
      "2       A-Channel        4    Dropped\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "\n",
    "# Define your file paths based on the folder structure in your image\n",
    "paths = {\n",
    "    # UPDATED: Pointing to the CSV file instead of XLSX\n",
    "    \"anilist_csv\": os.path.join(\"Datasets\", \"Holy_Dataset\", \"anilist_anime_data_complete.csv\"),\n",
    "    \"mal_csv\": os.path.join(\"Datasets\", \"anime-dataset-2023.csv\"),\n",
    "    \"offline_db_json\": os.path.join(\"Datasets\", \"anime-offline-database.json\"),\n",
    "    \"user_xml\": os.path.join(\"Datasets\", \"anilist.xml\")\n",
    "}\n",
    "\n",
    "def load_all_data():\n",
    "    print(\"--- Loading Datasets ---\")\n",
    "\n",
    "    # 1. Load the AniList CSV File (Holy_Dataset)\n",
    "    try:\n",
    "        print(f\"Loading AniList data from {paths['anilist_csv']}...\")\n",
    "        # UPDATED: Using read_csv instead of read_excel\n",
    "        df_anilist = pd.read_csv(paths['anilist_csv'])\n",
    "        print(f\"✅ Loaded AniList Data: {df_anilist.shape[0]} rows\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading AniList CSV: {e}\")\n",
    "        df_anilist = pd.DataFrame()\n",
    "\n",
    "    # 2. Load the MAL CSV File\n",
    "    try:\n",
    "        print(f\"Loading MAL data from {paths['mal_csv']}...\")\n",
    "        df_mal = pd.read_csv(paths['mal_csv'])\n",
    "        print(f\"✅ Loaded MAL Data: {df_mal.shape[0]} rows\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading MAL CSV: {e}\")\n",
    "        df_mal = pd.DataFrame()\n",
    "\n",
    "    # 3. Load the Anime Offline Database (JSON)\n",
    "    try:\n",
    "        print(f\"Loading Offline Database from {paths['offline_db_json']}...\")\n",
    "        with open(paths['offline_db_json'], 'r', encoding='utf-8') as f:\n",
    "            data_json = json.load(f)\n",
    "        \n",
    "        if 'data' in data_json:\n",
    "            df_offline = pd.DataFrame(data_json['data'])\n",
    "        else:\n",
    "            df_offline = pd.DataFrame(data_json)\n",
    "            \n",
    "        print(f\"✅ Loaded Offline DB: {df_offline.shape[0]} rows\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading JSON: {e}\")\n",
    "        df_offline = pd.DataFrame()\n",
    "\n",
    "    # 4. Load Personal User XML Data (anilist.xml)\n",
    "    try:\n",
    "        print(f\"Loading User XML from {paths['user_xml']}...\")\n",
    "        tree = ET.parse(paths['user_xml'])\n",
    "        root = tree.getroot()\n",
    "\n",
    "        xml_data = []\n",
    "        for anime in root.findall('anime'):\n",
    "            entry = {}\n",
    "            for child in anime:\n",
    "                entry[child.tag] = child.text\n",
    "            xml_data.append(entry)\n",
    "\n",
    "        df_user = pd.DataFrame(xml_data)\n",
    "        print(f\"✅ Loaded User Data: {df_user.shape[0]} entries\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading User XML: {e}\")\n",
    "        df_user = pd.DataFrame()\n",
    "\n",
    "    return df_anilist, df_mal, df_offline, df_user\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the loader\n",
    "    anilist_df, mal_df, offline_df, user_df = load_all_data()\n",
    "\n",
    "    # Preview the data\n",
    "    print(\"\\n--- Previews ---\")\n",
    "    if not anilist_df.empty:\n",
    "        print(\"\\nAniList Sample:\")\n",
    "        # Adjusting column names to likely CSV headers (may vary slightly from Excel)\n",
    "        cols_to_show = [col for col in ['title_english', 'averageScore', 'popularity'] if col in anilist_df.columns]\n",
    "        print(anilist_df[cols_to_show].head(3))\n",
    "    \n",
    "    if not user_df.empty:\n",
    "        print(\"\\nUser List Sample:\")\n",
    "        print(user_df[['series_title', 'my_score', 'my_status']].head(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
